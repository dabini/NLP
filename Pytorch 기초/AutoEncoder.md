# AutoEncoder

### Overview

- 인코더와 디코더를 통해 **압축과 해제**를 실행

  - 인코더는 입력(x)의 정보를 최대한 보존하도록 손실 압축을 수행
  - 디코더는 중간 결과물(z)의 정보를 입력(x)와 같아지도록 압축 해제(복원)을 수행

- 복원을 성공적으로 하기 위해,

  오토인코더는 특징을 추출하는 방법을 자동으로 학습

  ![image-20200805202741195](C:\Users\multicampus\NLP\Pytorch 기초\image-20200805202741195.png)

### Encoder

- 복원에 필요한 정보를 중심으로 손실 압축을 수행

  - 필요 없는 정보는 버릴 수도 있음

    ![image-20200805203423633](C:\Users\multicampus\NLP\Pytorch 기초\image-20200805203423633.png)

### Bottleneck

- 입력 (x)에 비해 작은 차원으로 구성
- 따라서 정보의 선택과 압축이 발생, 차원에 따라 압축의 정도를 결정함
  - 집에 불이 나서 탈출할 때, 무엇을 들고 나갈 것인가?
- 그러므로 z는 입력(x)에 대한 feature vectore라고 할 수 있다.
  - 압축의 효율이 높아야하므로, 입력에 비해 dense vector이다.

### Decoder

- 압축된 중간 결과물(z)를 바탕으로 최대한 입력(x)과 비슷하게 복원: xhat
  - 보통 MSELoss를 통해 최적화 수행
- 뻔한 정보는 주어지지 않더라고 어차피 알 수 있기에 복원 가능























































